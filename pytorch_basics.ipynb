{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXfSoqiBoJx4bZ9N3J9bmj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LI-bV2OO174N","executionInfo":{"status":"ok","timestamp":1691880864101,"user_tz":-60,"elapsed":4901,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"f67c2c76-fe09-4927-a60b-23ca6e4aa652"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","print(torch.__version__)"]},{"cell_type":"markdown","source":["## Introduction to tensors\n","\n","Now we've got PyTorch imported, it's time to learn about tensors.\n","\n","Tensors are the fundamental building block of machine learning.\n","\n","Their job is to represent data in a numerical way.\n","\n","For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n","\n","![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n","\n","In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for `colour_channels`, `height` and `width`.\n","\n","But we're getting ahead of ourselves.\n","\n","Let's learn more about tensors by coding them.\n"],"metadata":{"id":"xDoUmMPF2-IM"}},{"cell_type":"code","source":["# Scalar\n","\n","scalar= torch.tensor(21)\n","\n","scalar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4CmwLKh2t-d","executionInfo":{"status":"ok","timestamp":1691880864102,"user_tz":-60,"elapsed":23,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"776caa88-52ce-46ee-926a-211116c80b93"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(21)"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["See how the above printed out `tensor(21)`?\n","\n","That means although `scalar` is a single number, it's of type `torch.Tensor`.\n","\n","We can check the dimensions of a tensor using the `ndim` attribute."],"metadata":{"id":"Mdzv3qp93UHT"}},{"cell_type":"code","source":["scalar.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fWyr6tg3RD8","executionInfo":{"status":"ok","timestamp":1691880864102,"user_tz":-60,"elapsed":21,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"3be38e2a-8412-477b-9a12-ab9df53b6ddc"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["What if we wanted to retrieve the number from the tensor?\n","\n","As in, turn it from `torch.Tensor` to a Python integer?\n","\n","To do we can use the `item()` method."],"metadata":{"id":"OifgkAvp31Vb"}},{"cell_type":"code","source":["# Get the Python number within a tensor (only works with one-element tensors)\n","\n","scalar.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWR30u7J3gHD","executionInfo":{"status":"ok","timestamp":1691880864102,"user_tz":-60,"elapsed":20,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"7477833d-1640-4e49-ab90-d96e853df84a"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Okay, now let's see a **vector**.\n","\n","A vector is a single dimension tensor but can contain many numbers.\n","\n","As in, you could have a vector `[3, 2]` to describe `[bedrooms, bathrooms]` in your house. Or you could have `[3, 2, 2]` to describe `[bedrooms, bathrooms, car_parks]` in your house.\n","\n","The important trend here is that a vector is flexible in what it can represent (the same with tensors)."],"metadata":{"id":"S6N3pcOg3-Ij"}},{"cell_type":"code","source":["#vector\n","\n","vector = torch.tensor([21,14,15])\n","\n","vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FloDoEN437qq","executionInfo":{"status":"ok","timestamp":1691880864103,"user_tz":-60,"elapsed":20,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"2fe8290c-2d24-4ae4-94b1-863e72d75032"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([21, 14, 15])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["vector.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Sa8CaHg4Jjy","executionInfo":{"status":"ok","timestamp":1691880864103,"user_tz":-60,"elapsed":19,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"b81a2e05-c259-4a0d-d31e-8b4aa4fd4182"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["vector.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00AS76lr4NXq","executionInfo":{"status":"ok","timestamp":1691880864104,"user_tz":-60,"elapsed":19,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"974b79e8-0968-4cbb-957c-bbcf2bb3ae3f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#matrix\n","\n","MATRIX = torch.tensor([[15,78], [56,12]])\n","\n","MATRIX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yag6gbQr4Tia","executionInfo":{"status":"ok","timestamp":1691880864104,"user_tz":-60,"elapsed":18,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"f32d3796-68bd-48cb-8aa6-40e92a9c5629"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[15, 78],\n","        [56, 12]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["MATRIX.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmhJsYGt4qYi","executionInfo":{"status":"ok","timestamp":1691880864104,"user_tz":-60,"elapsed":17,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"282abd2b-41d6-4eb8-9879-7d8bbcb40ea4"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["MATRIX.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnviEqbB4yIJ","executionInfo":{"status":"ok","timestamp":1691880864104,"user_tz":-60,"elapsed":16,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"2a12b1fb-cd50-46b6-9e52-05d6cd3c1697"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Tensor\n","TENSOR = torch.tensor([[[1, 2, 3],\n","                        [3, 6, 9],\n","                        [2, 4, 5]]])\n","TENSOR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_P7I9Zy95DV5","executionInfo":{"status":"ok","timestamp":1691880864105,"user_tz":-60,"elapsed":16,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"95c005d8-c123-4478-c336-16b2900ac816"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1, 2, 3],\n","         [3, 6, 9],\n","         [2, 4, 5]]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["TENSOR.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xA_ZYaN5Sxa","executionInfo":{"status":"ok","timestamp":1691880864105,"user_tz":-60,"elapsed":14,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"c5f63377-e4d2-4191-f4af-227b33c56846"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["TENSOR.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnzEbjRD5n76","executionInfo":{"status":"ok","timestamp":1691880864106,"user_tz":-60,"elapsed":14,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"45ef75e3-d62c-4e2d-bb97-0edfaf7cbbfb"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["That means there's 1 dimension of 3 by 3.\n","\n","![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n"],"metadata":{"id":"mHqUM7pT54_q"}},{"cell_type":"markdown","source":["### Random tensors\n","\n","We've established tensors represent some form of data.\n","\n","And machine learning models such as neural networks manipulate and seek patterns within tensors.\n","\n","But when building machine learning models with PyTorch, it's rare you'll create tenors by hand (like what we've being doing).\n","\n","Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n","\n","In essence:\n","\n","`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n","\n","As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n","\n","We'll get hands on with these steps later on.\n","\n","For now, let's see how to create a tensor of random numbers.\n","\n","We can do so using [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) and passing in the `size` parameter."],"metadata":{"id":"vOM5yPtf6WQR"}},{"cell_type":"code","source":["# random tensors\n","\n","\n","random_tensor = torch.rand(4,5)\n","print(random_tensor)\n","print(f\"data types: {random_tensor.dtype}\")\n","print(f\"ndim : {random_tensor.ndim}\")\n","print(f\"shape : {random_tensor.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qx4Zct-85sKB","executionInfo":{"status":"ok","timestamp":1691880864106,"user_tz":-60,"elapsed":13,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"40cfba00-d5fc-419f-de67-627c42924ea8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6886, 0.6328, 0.4783, 0.0424, 0.1697],\n","        [0.9300, 0.7749, 0.1338, 0.2350, 0.7072],\n","        [0.0291, 0.8378, 0.3842, 0.9622, 0.8127],\n","        [0.6878, 0.4483, 0.4441, 0.3209, 0.8834]])\n","data types: torch.float32\n","ndim : 2\n","shape : torch.Size([4, 5])\n"]}]},{"cell_type":"markdown","source":["The flexibility of `torch.rand()` is that we can adjust the `size` to be whatever we want.\n","\n","For example, say you wanted a random tensor in the common image shape of `[224, 224, 3]` (`[height, width, color_channels`])."],"metadata":{"id":"d8gm3ONK8eRC"}},{"cell_type":"code","source":["# Create a random tensor of size (224, 224, 3)\n","random_image_size_tensor = torch.rand(size=(224, 224, 3))\n","random_image_size_tensor.shape, random_image_size_tensor.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y7oPRYB07zbh","executionInfo":{"status":"ok","timestamp":1691880864106,"user_tz":-60,"elapsed":12,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"aaf0ae46-4439-4cae-8443-a1a0c5a58290"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([224, 224, 3]), 3)"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["#Zeros and ones\n","\n","Let's create a tensor full of zeros with torch.zeros()"],"metadata":{"id":"Ytj02f-YfRwA"}},{"cell_type":"code","source":["# create zeros\n","\n","zeros = torch.zeros(size=(2,3,4))\n","\n","zeros"],"metadata":{"id":"vOPSNX1c8cMA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691880864107,"user_tz":-60,"elapsed":12,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"ea0ed681-3bd0-4f7d-c096-49dfbbb72e27"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]],\n","\n","        [[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["ones = torch.ones(size = (2,4))\n","ones"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Quwgi1iAfk9o","executionInfo":{"status":"ok","timestamp":1691880864107,"user_tz":-60,"elapsed":11,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"6d0c5aac-ae82-4c21-cd4f-afbb7ea7d1ab"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["### Creating a range and tensors like\n","\n","Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n","\n","You can use `torch.arange(start, end, step)` to do so.\n","\n","Where:\n","* `start` = start of range (e.g. 0)\n","* `end` = end of range (e.g. 10)\n","* `step` = how many steps in between each value (e.g. 1)\n","\n","> **Note:** In Python, you can use `range()` to create a range. However in PyTorch, `torch.range()` is deprecated and may show an error in the future."],"metadata":{"id":"pLNqygdz9VhQ"}},{"cell_type":"code","source":["torch.arange(0,10)"],"metadata":{"id":"MOV7SEVUf2ew","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691880979898,"user_tz":-60,"elapsed":195,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"20e34b88-b883-4158-c07a-6ff43394f263"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["torch.arange(0,200,17)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3yIp8zr9rDI","executionInfo":{"status":"ok","timestamp":1691881076898,"user_tz":-60,"elapsed":2,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"76cbf53c-ae2c-4bf0-d4a4-3f66ee44eb17"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  0,  17,  34,  51,  68,  85, 102, 119, 136, 153, 170, 187])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# Use torch.arange(), torch.range() is deprecated\n","zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n","\n","# Create a range of values 0 to 10\n","zero_to_ten = torch.arange(start=0, end=10, step=1)\n","zero_to_ten"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH-kfGci94F5","executionInfo":{"status":"ok","timestamp":1691881040072,"user_tz":-60,"elapsed":307,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"ab175174-63bc-4005-ddcb-0de9d06cacf9"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-a09072c806d9>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n","\n","For example, a tensor of all zeros with the same shape as a previous tensor.\n","\n","To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."],"metadata":{"id":"D2uIFNmt-D9R"}},{"cell_type":"code","source":["# Can also create a tensor of zeros similar to another tensor\n","ten_zeros = torch.ones_like(input=zero_to_ten) # will have same shape\n","ten_zeros"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoGapki29-XX","executionInfo":{"status":"ok","timestamp":1691881273669,"user_tz":-60,"elapsed":199,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"2667542a-f920-420b-f848-fdb9ce5ab1d0"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["### Tensor datatypes\n","\n","There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n","\n","Some are specific for CPU and some are better for GPU.\n","\n","Getting to know which is which can take some time.\n","\n","Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n","\n","The most common type (and generally the default) is `torch.float32` or `torch.float`.\n","\n","This is referred to as \"32-bit floating point\".\n","\n","But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n","\n","And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n","\n","Plus more!\n","\n","> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n","\n","The reason for all of these is to do with **precision in computing**.\n","\n","Precision is the amount of detail used to describe a number.\n","\n","The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n","\n","This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n","\n","So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n","\n","> **Resources:**\n","  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n","  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n","\n","Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."],"metadata":{"id":"0GRj9qpp-7Pg"}},{"cell_type":"code","source":["# Default datatype for tensors is float32\n","float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n","                               device=\"cpu\", # defaults to None, which uses the default tensor type\n","                               requires_grad=False) # if True, operations performed on the tensor are recorded\n","\n","float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYiSma6z-m6X","executionInfo":{"status":"ok","timestamp":1691881846430,"user_tz":-60,"elapsed":253,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"8b4c7207-1140-4b0b-9c17-9afd2a09029b"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3]), torch.float32, device(type='cpu'))"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n","\n","For example, one of tensors is `torch.float32` and the other is `torch.float16` (PyTorch often likes tensors to be the same format).\n","\n","Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n","\n","We'll see more of this device talk later on.\n","\n","For now let's create a tensor with `dtype=torch.float16`."],"metadata":{"id":"kxD0uCXbBaqJ"}},{"cell_type":"code","source":["float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=torch.float16) # torch.half would also work\n","\n","float_16_tensor.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"125r81hp_Xrg","executionInfo":{"status":"ok","timestamp":1691881954321,"user_tz":-60,"elapsed":200,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"5986b658-5e66-4cc8-8dc4-3c2577d8752a"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float16"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["## Getting information from tensors\n","\n","Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n","\n","We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n","* `shape` - what shape is the tensor? (some operations require specific shape rules)\n","* `dtype` - what datatype are the elements within the tensor stored in?\n","* `device` - what device is the tensor stored on? (usually GPU or CPU)\n","\n","Let's create a random tensor and find out details about it."],"metadata":{"id":"wQ9gpCfZB14L"}},{"cell_type":"code","source":["# Create a tensor\n","some_tensor = torch.rand(3, 4)\n","\n","# Find out details about it\n","print(some_tensor)\n","print(f\"Shape of tensor: {some_tensor.shape}\")\n","print(f\"Datatype of tensor: {some_tensor.dtype}\")\n","print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFEMSvr1BdlY","executionInfo":{"status":"ok","timestamp":1691882127835,"user_tz":-60,"elapsed":205,"user":{"displayName":"naveen kadampally","userId":"11540917112415081866"}},"outputId":"d289425d-f841-4dc1-87b3-47689af94afc"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6554, 0.3816, 0.7045, 0.9371],\n","        [0.0313, 0.2054, 0.6743, 0.8969],\n","        [0.3596, 0.5750, 0.8230, 0.3716]])\n","Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}]},{"cell_type":"markdown","source":["> **Note:** When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n","  * \"*what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where*\""],"metadata":{"id":"LVa58FNsCr6S"}},{"cell_type":"markdown","source":["## Manipulating tensors (tensor operations)\n","\n","In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n","\n","A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n","\n","These operations are often a wonderful dance between:\n","* Addition\n","* Substraction\n","* Multiplication (element-wise)\n","* Division\n","* Matrix multiplication\n","\n","And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n","\n","Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."],"metadata":{"id":"urDczcwMC0rC"}},{"cell_type":"code","source":[],"metadata":{"id":"osRM4YwrCH8i"},"execution_count":null,"outputs":[]}]}